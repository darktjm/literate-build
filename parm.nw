% -*- mode: Noweb; noweb-code-mode: c-mode; -*-
% Build with noweb:
%  notangle -t8 build.nw > makefile
%  make
% or:  see build section below.
%%% requires build
\documentclass[twoside,english]{article}
\usepackage[letterpaper,rmargin=1.5in,bmargin=1in]{geometry}
\usepackage{noweb}
\noweboptions{smallcode,longchunks}
%%% latex preamble
\usepackage{hyperref}

\begin{document}

\title{Parameterized Chunks for noweb}
\author{Thomas J. Moore}
\date{Version 1.01\\23 July, 2013}
\maketitle

This document is placed in the public domain in 2021 by Thomas J. Moore.

\tableofcontents

\section{Introduction}

I like to consolidate code as much as possible.  I do this in C using
either subroutines or preprocessor macros.  The macros are more useful
when the number of inputs and/or outputs are large, or using a macro
is significantly faster.  The subroutines cannot even be used when
doing something like defining a large number of similar symbols, or
providing a more convenient way to define data tables.  The
preprocessor can usually accomplish what I need, but the price is that
the debugger cannot debug code defined by the preprocessor.  In
addition, there are some languages which lack a preprocessor.  As
such, the original Web system had macros with arguments, and I would
like something similar.

% Begin-doc nw-enh-syntax
I propose the following syntax changes:

\begin{itemize}

\item A chunk name used in a chunk definition line may contain
parameter definitions in parentheses.  All parameter names begin with
an at-sign (@).  The only characters forbidden in parameter names are
close-parentheses and invalid noweb syntax.  Thus the parameter name
is terminated by its closing parenthesis.  Parameter definition syntax
within in-line code is ignored.

For example:
\begin{quote}
\begin{verbatim}
@<<macro (@arg1) with -(@arg2)- (but not @[[(@arg3)]])>>=
text
@@
\end{verbatim}
\end{quote}

The parameters are [[@arg1]] and [[@arg2]].

\item No chunk name may begin with an at-sign (@).  That is, the names
starting with an at-sign are reserved for parameter names.

\item Chunk references beginning with an at-sign (@) expand to the
parameter with that name, as defined by the closest parent taking a
parameter of that name.  When weaved, such references are not linked
anywhere, and they are not added to the index.  When tangled, the
[[-L]] option is ignored.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
text @<<@arg>>
@<<other>>
@@
@<<macro2 (@arg)>>=
text2 @<<@arg>>
@<<other>>
@@
@<<other>>=
@<<@arg>>
@@
\end{verbatim}
\end{quote}

When expanded within [[macro]], both [[@arg]] and [[other]] will
expand using [[macro]]'s argument.  When expanded within [[macro2]],
both [[@arg]] and [[other]] will expand using [[macro2]]'s argument.

\item A chunk reference consisting of the name of a chunk taking
parameters, with all parameter references replaced by noweb in-line
code segments, represents an expansion of the reference with the
parameters taking the value of the code within the in-line code
segments in their respective positions.  No expansion is done within
the code segments except for parameter references; these may be used
to pass parameters on to another macro.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
text @<<@arg>>
@@
@<<macro2 (@arg)>>=
@<<macro @[[and @<<@arg>>]]>>
@@
@<<macro3 (@arg)>>=
@<<macro4>>
@@
@<<macro4>>=
can reference @<<@arg>> of macro3.
@@
@<<caller>>=
text @<<macro @[[text2]]>> @<<macro2 @[[text3]]>>
@<<macro3 @[[text4]]>>
@@
\end{verbatim}
\end{quote}

The [[caller]] chunk expands to

\begin{quote}
\begin{verbatim}
text text text2 text and text3
can reference text4 of macro3.
\end{verbatim}
\end{quote}

\item When more than one parameterized chunk could be used to replace
a reference, the one with the least parameter replacements is chosen.
For equal numbers, the one which does not contain the earliest
parameter replacement is chosen.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg1) and (@arg2)>>=
text @<<@arg1>> blah @<<@arg2>>
@@
@<<macro @[[1]] and (@arg)>>=
text blah blah @<<@arg>>
@@
@<<macro (@arg) and @[[2]]>>=
text blah blah blah @<<@arg>>
@@
@<<*>>=
@<<macro @[[a]] and @[[b]]>> -- one blah
@<<macro @[[1]] and @[[b]]>> -- two blahs
@<<macro @[[a]] and @[[2]]>> -- three blahs
@<<macro @[[1]] and @[[2]]>> -- two blahs and a warning
@@
\end{verbatim}
\end{quote}

\item For literal text matching, all passed-on variable references are
expanded first.

For example:

\begin{quote}
\begin{verbatim}
@<<macro (@arg)>>=
1 @<<@arg>>
@@
@<<macro @[[x y]]>>=
1 z
@@
@<<macro2 (@arg)>>=
@<<macro @[[x @<<@arg>>]]>>
@@
@<<*>>=
@<<macro2 @[[x]]>> -- 1 x x
@<<macro2 @[[y]]>> -- 1 z
@@
\end{verbatim}
\end{quote}

\end{itemize}
% End-doc nw-enh-syntax

\section{Tangling}

Rather than create an entirely new tangler, the noweb pipeline is
used.  Also, rather than modifying the noweb tangler, a filter is
created.  A filter is less efficient than simply replacing the
tangler, but it is compatible with both noweb 2 and 3.

While I would prefer to write this in C, I have decided to use C++
instead.  The main advantage is that C++ has usable variable-sized
strings, arrays and hash tables in the standard, whereas I'd have to
reimplement these or use something like GLib (which is not easy to
locate on systems that don't have [[pkg-config]]).  Even C++ has
issues with respect to whether or not the STL is usable at all, or
what standard the installed compiler complies with.  My system is
modern and up-to-date, but I have at least tried to make this
compatible with C++-98 through C++-20 without errors or warnings.

%\lstset{language=C++}
<<Common parm C++ Prefix>>=
/***************************
  GENERATED FILE:  DO NOT EDIT OR READ THIS FILE
  Instead, read or edit the noweb file(s) from which this was generated.
****************************/
#include <vector>
#include <string>
#include <iostream>
#include <map>
extern "C" {
#include <stdlib.h>
}
#if __cplusplus < 201100L
#define unordered_map map
#else
#include <unordered_map>
#endif

using namespace std;
typedef unordered_map<string, string> strmap;
@

<<nt-parm.cpp>>=
<<Common parm C++ Prefix>>

<<[[nt-parm]] local definitions>>

int main(void)
{
  <<Gather code chunks from noweb pipeline>>

  <<Mangle and dump pipeline>>
  return 0;
}
@

Tangling a parameterized chunk is done by duplicating the chunk
definition for every unique reference, replacing parameters as
necessary.  Since the above definition allows chunks expanded within
the parameterized chunk (recursively) to also expand the same
parameters, they may need to be duplicated as well.  Chunk references
in the unduplicated code do not need to be modified, since the newly
created chunk names match their usage.  In fact, the original input
can be safely dumped unmodified to the output.

All definition text is slurped into a single array ([[notext]]).
Since we only care about chunk definition and reference lines, array
indices are only incremented when such lines are found.

When duplicating a definition, the original file and line location are
needed.  When parsing a reference, the original file and line location
may be needed for error messages.  Rather than store these in separate
locations for each, a couple of arrays are added ([[textfile]],
[[textline]]), and the file and line for any particular definition or
usage text array element is stored in the side arrays with the same
index.  There is no need to assign valid values to unused indicies, since
they will never be referenced, but C++ does insist on intializing them
to someting (blank/0).

<<[[nt-parm]] local definitions>>=
vector<string> notext, textfile;
vector<int> textline;
@

<<Common parm C++ Prefix>>=
#define cmp_prefix(s) compare(0, sizeof(s) - 1, s)
#define line_cmp_prefix_sp_or_nl(s) \
  (line.cmp_prefix(s) || \
   (line[sizeof(s) - 1] != ' ' && line[sizeof(s) - 1] != '\n'))
#define ltail(s, n) s.substr(n, s.size() - (n + 1))
@

<<Gather code chunks from noweb pipeline>>=
int lineno = 1;
string file = "<stdin>";
int codeline = 0;
string codefile, curchunk;
notext.push_back("");
string line;
while(getline(cin, line).good() || line.size()) {
  line += '\n';
  cout @<< line;

  if(!line_cmp_prefix_sp_or_nl("@begin code")) {
    codeline = lineno;
    codefile = file;
    notext.push_back(line);
  } else if(!line.cmp_prefix("@defn ")) {
    if(!codeline) {
      cerr @<< file @<< ':' @<< lineno @<< ": invalid chunk syntax\n";
      exit(1);
    }
    if(line[6] == '@') {
      cerr @<< file @<< ':' @<< lineno @<< ": "
              "initial @ is reserved for parameter names\n";
      cout @<< "@nl\n@end code\n"; // prevent malformed code messages
      cout @<< "@fatal invalid chunk name\n";
      exit(1);
    }
    curchunk = ltail(line, 6);
    notext.back() += line;
    // C++ won't fill in missing elements
    textfile.insert(textfile.end(), notext.size() - textfile.size() - 1, "");
    textline.insert(textline.end(), notext.size() - textline.size() - 1, 0);
    textfile.push_back(file);
    textline.push_back(lineno);
    <<Store [[curchunk]] info>>
    notext.push_back("");
  } else if(!line_cmp_prefix_sp_or_nl("@end code")) {
    if(curchunk.empty()) {
      cerr @<< file @<< ':' @<< lineno @<< ": invalid chunk syntax\n";
      exit(1);
    }
    notext.back() += line;
    <<Finish off [[curchunk]]>>
    notext.push_back("");
    codeline = 0;
    codefile = curchunk = "";
  } else if(!line.cmp_prefix("@use ")) {
    if(!curchunk.empty()) {
      notext.push_back(line);
      // C++ won't fill in missing elements
      textfile.insert(textfile.end(), notext.size() - textfile.size() - 1, "");
      textline.insert(textline.end(), notext.size() - textline.size() - 1, 0);
      textfile.push_back(file);
      textline.push_back(lineno);
      notext.push_back("");
    }
  } else if(!line_cmp_prefix_sp_or_nl("@fatal"))
    exit(1);
  else if(!line_cmp_prefix_sp_or_nl("@nl") ||
          !line_cmp_prefix_sp_or_nl("@index nl")) {
    lineno++;
    if(codeline)
      notext.back() += line;
  } else if(!line.cmp_prefix("@file ")) {
    file = ltail(line, 6);
    lineno = 1;
    if(codeline)
      notext.back() += line;
  } else if(!line.cmp_prefix("@line ")) {
    lineno = stoi(line.substr(6)) - 1;
    if(codeline)
      notext.back() += line;
  } else if(codeline)
    notext.back() += line;
}
@

<<[[nt-parm]] local definitions>>=
#if __cplusplus < 201100L
int stoi(const string &s)
{
  return atoi(s.c_str());
}
#endif
@

A separate map ([[chunks]]) stores, for each unique name, a list of
all definitions' text array start and end indicies.  This is stored in
a single vector as two consecutive entries for each chunk.

<<[[nt-parm]] local definitions>>=
unordered_map<string, vector<int> > chunks;
@

<<Store [[curchunk]] info>>=
chunks[curchunk].push_back(notext.size() - 1);
@

<<Finish off [[curchunk]]>>=
chunks[curchunk].push_back(notext.size() - 1);
@

Since normal code syntax is used for parameter values, special care
must be taken to distinguish them.  This is done by first scanning for
a chunk which exactly matches the reference.  If this is not found,
parameterized functions are searched, with the most explicit one
matching.  For the second step, a filter is applied to replace in-line
code and parameter definitions with placeholders to create the key for
a map of stripped names ([parmchunks]]).  Each map value is a
list of definition names with the same key.  This reduces the number
of chunk names that need to be checked every time a potential
expansion is found.  Note that the list of names is in the form of a
set; this is so duplicates can be removed without thinking.

<<Common parm C++ Prefix>>=
#include <set>
#if __cplusplus < 201100L
#define unordered_set set
#else
#include <unordered_set>
#endif
// for testing, it's better for strset to be in a predicatable order
typedef /*unordered_*/set<string> strset;
typedef unordered_map<string, strset> strsetmap;
@

<<[[nt-parm]] local definitions>>=
strsetmap parmchunks;
<<[[strip_chunkname]]>>
@

<<[[strip_chunkname]]>>=
// Perl code used a recursive re for this, but C++ regex doesn't do recursion
// extract next (@...) or [[....]] starting at after, returning start of
// parm and position after parm and returns true if found
// returns false if not found and updates start and after in unpredictable ways
static bool find_parm(const string &s, int &start, int &after)
{
  int len = s.size();
  // perl code allowed just @ as a symbol, so I guess I'll do the same here
  for(; len - after >= 3; after++) {
    if(s[after] == '(' && s[after + 1] == '@') {
      start = after;
      for(after += 2; after < len; after++)
        if(s[after] == ')') {
	  ++after;
	  return true;
	}
      // perl re backtracked here and continued scanning for code literals
      // but that shouldn't really have been allowed, anyway
      return false;
    }
    // No way to escape (@..), but @ escapes [[.
    if(s[after] == '@' && s[after + 1] == '[' && s[after + 2] == '[') {
      after += 2; // as per old code, but really should just be after++
      continue;
    }
    // perl re ignored this entirely and tried again later if brackets weren't
    // properly nested
    // again, that shouldn't really have been allowed, anyway
    if(s[after] == '[' && s[after + 1] == '[') {
      start = after;
      int nest = 0;
      for(after += 2; len - after >= 2 &&
                      (nest || s[after] != ']' || s[after + 1] != ']');
		        after++) {
        if(s[after] == '[')
	  nest++;
	else if(nest && s[after] == ']')
	  nest--;
      }
      if(len - after < 2)
        return false;
      after += 2;
      return true;
    }
  }
  return false;
}

static string strip_chunkname(const string &s)
{
  string ret = s;
  for(int after = 0, start; find_parm(ret, start, after); after = start + 3)
    ret.replace(start, after - start, "(@)");
  return ret;
}
@

<<Store [[curchunk]] info>>=
string strip = strip_chunkname(curchunk);
parmchunks[strip].insert(curchunk);
@

Once all has been collected, the duplicated chunks can be dumped. This
is done by iterating through the array, looking for [[@use]]es.  Any
[[@use]] which is already present in [[chunks]] is left alone.
Otherwise, if there is a match to a parameterized name (i.e. an entry
in [[parmchunks]] for the stripped name), the best such name is found
and dumped using the use-name.

<<Mangle and dump pipeline>>=
for(size_t i = 0; i < notext.size(); i++) {
  string &u = notext[i];
  if(u.cmp_prefix("@use "))
    continue;
  string curchunk = ltail(u, 5);
  if(chunks.find(curchunk) != chunks.end())
    continue;
  string best;
  strmap best_parms;
  best = find_best_def(idx_to_loc(i), curchunk, best_parms);
  if(best.empty())
    continue;
  <<Dump best definition match for [[curchunk]]>>
}
@

<<[[nt-parm]] local definitions>>=
<<[[find_best_def]]>>

#define idx_to_loc(idx) (textfile[idx] + ':' + to_string(textline[idx]) + ": ")
#include <sstream>
#if __cplusplus < 201100L
string to_string(int i)
{
  stringstream ret;
  ret << i;
  return ret.str();
}
#endif
@

<<[[find_best_def]]>>=
static string find_best_def(const string &loc, const string &curchunk,
			    strmap &best_parms)
{
  strsetmap::const_iterator pci = parmchunks.find(strip_chunkname(curchunk));
  if(pci == parmchunks.end())
    return "";
  const strset &pchunks = pci->second;
  <<Find best definition match for [[curchunk]] in [[pchunks]]>>
}
@

Each possible expansion is checked, keeping the best.  While it's
doing that, since it already has the parameter names and their values
parsed out, a symbol table is built for the parameters.  As you may
have noticed above, the symbol table is returned along with the
matched chunk name.

<<Find best definition match for [[curchunk]] in [[pchunks]]>>=
string best;
<<Prepare for finding best definition match>>
for(strset::const_iterator may = pchunks.begin(); may != pchunks.end(); may++) {
  strmap may_parms;
  <<Check [[may]] and collect parameter defs into [[may_parms]]>>
  <<[[continue]] if [[may]] is not best>>
  best = *may;
  best_parms = may_parms;
  <<Save additional best info about [[may]]>>
}
<<Finish up after finding best definition match>>
return best;
@

Checking for a match involves simultaneously iterating over the replaced
portions of the names.  If the replaced portion of both names matches,
it's considered a match (even if both are in the parameter definition
form, although perhaps that should be an error).  If they do not
match exactly, they still match if the definition side is in parameter
definition form, and the usage side is in literal code text form.

<<Check [[may]] and collect parameter defs into [[may_parms]]>>=
<<Prepare to check if definition matches>>
int mayrest = 0, ccrest = 0, maystart, ccstart;
bool found;
while((found = find_parm(*may, maystart, mayrest))) {
  <<Prepare for resolving ambiguity per match>>
  find_parm(curchunk, ccstart, ccrest);
  if(!curchunk.compare(ccstart, ccrest - ccstart, *may, maystart, mayrest - maystart))
    continue;
  if((*may)[maystart] == '[' || curchunk[ccstart] == '(')
    break; // continue may loop

  string mayp = may->substr(maystart, mayrest - maystart);
  string curp = curchunk.substr(ccstart, ccrest - ccstart);
  <<Store found parameter in [[curchunk]] in [[may]]>>
}
if(found) // break from prev loop:  continue may loop
  continue;
@

<<Store found parameter in [[curchunk]] in [[may]]>>=
may_parms[may->substr(maystart + 1, mayrest - maystart - 2)] =
   curchunk.substr(ccstart + 2, ccrest - ccstart - 4);
@

To resolve ambiguity, the name with the fewest substitutions is
retained.

<<Prepare for finding best definition match>>=
int best_len = curchunk.size(); // larger than all possible lengths
@

<<Prepare to check if definition matches>>=
int len = 0;
@

<<Store found parameter in [[curchunk]] in [[may]]>>=
len++;
@

<<[[continue]] if [[may]] is not best>>=
if(len > best_len)
  continue;
@

<<Save additional best info about [[may]]>>=
best_len = len;
@

If two names have an equal number of substitutions, the one which has
in-line code at the first position where the two differ is chosen, and
a warning is issued.  If two names have an equal number of
substitutions, and all are in the same places, then there is an
unresolvable ambiguity, leading to error exit.

<<Prepare for finding best definition match>>=
vector<int> best_parms_loc;
vector<string> ambig;
bool bad_ambig = false;
@

<<Prepare to check if definition matches>>=
vector<int> may_parms_loc;
int parm_loc = 0;
@

<<Prepare for resolving ambiguity per match>>=
parm_loc++;
@

<<Store found parameter in [[curchunk]] in [[may]]>>=
may_parms_loc.push_back(parm_loc);
@

<<[[continue]] if [[may]] is not best>>=
if(len == best_len) {
  if(!ambig.size())
    ambig.push_back(best);
  ambig.push_back(*may);
  size_t i;
  for(i = 0; i < may_parms_loc.size(); i++) {
    if(may_parms_loc[i] < best_parms_loc[i]) {
      i = ~0UL; // continue may loop
      break;
    }
    if(may_parms_loc[i] > best_parms_loc[i])
      break;
  }
  if(i == ~0UL)
    continue;
  if((bad_ambig = i == may_parms_loc.size())) {
    best = "";
    continue;
  }
} else {
  ambig.clear();
  bad_ambig = false;
}
@

<<Save additional best info about [[may]]>>=
best_parms_loc = may_parms_loc;
@

<<Finish up after finding best definition match>>=
if(ambig.size()) {
  cerr @<< loc;
  if(bad_ambig)
    cerr @<< "fatal: unresolvable ";
  cerr @<< "ambiguous expansion of @<<" @<< curchunk @<< "@>>:\n";
  for(vector<string>::const_iterator may = ambig.begin(); may != ambig.end(); may++) {
    cerr @<< "  @<<" @<< *may @<< "@>>";
    if(*may == best)
      cerr @<< " (chosen)";
    cerr @<< '\n';
  }
  if(bad_ambig) {
    cout @<< "@fatal ambiguous expansion\n";
    exit(1);
  }
}
@

Technically, there are hidden [[@use]] references within the reference
name, in the form of explicitly passed down parameters.  At the top
level, these should always generate errors, since no parameters have
been defined yet.  However, since we're dumping chunks whether they
are used or not, the error cannot be printed.  I suppose emitting an
explicit [[@use]] just after the reference would cause notangle to
emit an error message, but instead, these are just left as is.  Some
of these references are in the main text anyway, and it's too late to
make changes to that since it's already been dumped.

<<Dump best definition match for [[curchunk]]>>=
#if 0
// since we're not notangle, we have to expand every single chunk
// so raising an error on unknown parm is not possible
// for now, just go ahead and leave unexpanded
for(auto v = best_params.begin(); v != best_params.end(); v++)
  for(size_t start, next = 0;
      (start = v->second.find("@<<", next)) != string::npos; )
    for(next = start + 2; (next = v->second.find("@>>", next)) != string::npos; )
      if(v->second[next -1] != '@') {
        cerr @<< textfile[i] @<< ':' @<< textline[i] @<< ": undefined parameter ";
        cerr @<< v->second->substr(start, next + 2 - start);
        break;
      }
#endif
@

While a chunk is dumped, any references within the dumped text must be
checked as well.  Thus, instead of printing the chunk immediately, it
is accumulated into a string, and dumped when finished.  References'
dumped defnitions are recursively gathered and then appended to the
final return string.

<<Dump best definition match for [[curchunk]]>>=
cout @<< dump_def(best, curchunk, best_parms);
@

<<[[nt-parm]] local definitions>>=
<<[[dump_def]] deps>>
static string dump_def(string &oldc, string &newc, strmap &parms)
{
  string ret, subdefs;
  <<Dump [[oldc]] as [[newc]] with [[parms]] into [[ret]]/[[subdefs]]>>
  return ret + subdefs;
}
@

Before dumping the definition, though, if it has already been dumped,
it should be skipped.  Above, the dumping was explicitly skipped if
the chunk was already defined, so the same check is used within
[[dump_def]], and those checks are enabled by defining a dummy chunk.

<<Dump [[oldc]] as [[newc]] with [[parms]] into [[ret]]/[[subdefs]]>>=
chunks[newc] = vector<int>();
@

The definition text to be dumped consists of all chunks for the
[[oldc]] definition.  Before each chunk's text emission, a [[@file]]
and [[@line]] directive is emitted, to keep [[-L]] working.  The first
[[notext]] entry for every chunk definition is the [[@defn]] line
itself and needs to be processed separately.  It is just dumped as is
with the old name replaced by the new name.  Other than that, only the
[[@use]] lines need special processing.

<<Dump [[oldc]] as [[newc]] with [[parms]] into [[ret]]/[[subdefs]]>>=
vector<int> chunk = chunks[oldc];
for(size_t c = 0; c < chunk.size(); c += 2) {
  int i = chunk[c], last = chunk[c + 1];
  ret += "@file " + textfile[i] + "\n@line " + to_string(textline[i] + 1) + '\n';
  ret += notext[i].substr(0, notext[i].size() - (oldc.size() + 1)) + newc + '\n';
  for(i++; i <= last; i++) {
    string t = notext[i];
    if(t.cmp_prefix("@use "))
      ret += t;
    else {
      <<Transform and add [[@use]] in [[t]] to [[ret]]/[[subdefs]]>>
    }
  }
}
@

Any [[@use]] which refers to a parameter is replaced immediately by
the literal parameter text value.  Due to the syntax of noweb chunk
names, there is never a newline in the value, so a single [[@text]] is
generated.

To dump a chunk, any [[@use]] references within the chunk must be
checked.  Those which refer to a parameter are replaced by the
parameter's value.  Those which refer to a chunk with parameter
expansions cause that chunk to be duplicated, as well, with the root
chunk name as a prefix, separated from the real name by something that
is unlikely to occur in real names ([[@<<@>>]]).  The current set of
parameters is tracked througout this process, so that parameter
references (even within parameter values) are properly expanded.
Naturally, the top-level reference can't use a parameter reference,
since no parameters are defined yet.

<<Transform and add [[@use]] in [[t]] to [[ret]]/[[subdefs]]>>=
if(t[5] == '@') {
  string var = ltail(t, 5);
  strmap::const_iterator valp = parms.find(var);
  if(valp != parms.end())
    ret += "@text " + valp->second + '\n';
  else {
#if 0
    // again, we're not notangle, so can't raise errors here
    cerr @<< err_loc @<<
            "undefined parameter @<<" @<< var @<< "@>>\n";
#else
    // but we can force notangle to raise an error:
    ret += t;
#endif
  }
@

Otherwise, if the chunk reference requires parameter processing, it
needs to be handled pretty much the same as in the main loop, except
that instead of (not) raising errors for parameter references within
values, they must be expanded.  If a parameter expansion results in a
more explicit match to a definition, that more explicit match is used
instead.

Note that exact matches give ``best'' definitions as well, so this
code will handle unparameterized calls as well, skipping the reference
substitution due to an empty [[best_parms]].

<<Transform and add [[@use]] in [[t]] to [[ret]]/[[subdefs]]>>=
} else {
  string new_chunk = ltail(t, 5);
  strmap best_parms;
  string best = find_best_def(idx_to_loc(i), new_chunk, best_parms);
  if(best.empty())
    continue;
  <<Handle dump of [[best]]>>
}
@

<<Handle dump of [[best]]>>=
recheck_best(idx_to_loc(i), new_chunk, best, best_parms, parms);
// add new parms to global set of parms for recursive call
strmap new_parms = merge_strmap(parms, best_parms);
@

<<[[dump_def]] deps>>=
static strmap merge_strmap(const strmap &first, const strmap &second)
{
  strmap ret = first;
  for(strmap::const_iterator it = second.begin(); it != second.end(); it++)
    ret[it->first] = it->second;
  return ret;
}
@

<<[[dump_def]] deps>>=
// substitute parm refs in chunk name and maybe find new best match
static void recheck_best(const string &err_loc, string &new_chunk, string &best,
                         strmap &best_parms, const strmap &parms)
{
  bool parms_changed = false;

  for(strmap::const_iterator p = best_parms.begin(); p != best_parms.end(); p++) {
    const string &v = p->second;
    string newv = "";
    size_t vrest = 0, start;
    while((start = v.find("@<<@", vrest)) != string::npos) {
      // note:  old per code did not accept @ escapes for @<<
#if 0 // so I won't here, either
      if(start > 0 && v[start - 1] == '@') {
        vrest = start + 1;
        continue;
      }
#endif
      size_t end = start;
      do {
        end = v.find("@>>", end + 2);
      } while(end != string::npos && v[end - 1] == '@');
      if(end == string::npos)
        break;
#if 0
      // once again, can't print error because we're not notangle
      // instead, silently ignore/replace with blanks
      if(parms.find(v.substr(start + 2, end - start - 2)) == parms.end())
        cerr @<< err_loc @<<
                 "undefined parameter " @<< v.substr(start, end + 2 - start) @<< '\n';
#endif
      newv += v.substr(vrest, start - vrest) +
              parms.find(v.substr(start + 2, end - start - 2))->second;
      vrest = end + 2;
    }
    newv += v.substr(vrest);
    if(newv != v) {
      //best_parms[p->first] = newv; // reset by find_best_def below
      for(size_t start = 0;
          (start = new_chunk.find("[[" + v + "]]", start)) != string::npos;
	  start++) {
        if(start && new_chunk[start - 1] == '@')
	  continue;
	new_chunk.replace(start + 2, v.size(), newv);
	start += newv.size() + 3;
      }
      parms_changed = true;
    }
  }
  // find better match if var replacements were made
  if(parms_changed) {
    best_parms.clear();
    best = find_best_def(err_loc, new_chunk, best_parms);
  }
}
@

Parameters are implicitly inherited by expanded chunks.  This changes
the text of those expanded chunks if they reference the implicitly
defined parameters, and requires that they be dumped as well.  Their
name needs to change to avoid conflict with existing symbols, in a
consistent way so that they do not need to be dumped more than once.
For now, this is done by prepending the root chunk name defining the
parameter it (or one of its expanded chunks) uses, separated from the
name by something that would be hard to add to a real chunk name:
$@<<>>$.

Referenced chunks will enter this code as well, adding their own name
to the already long chunk name.  This could be prevented by passing in
a prefix, and only updating that prefix when a parameterized chunk
name is encountered whose parameters are specifically referenced.
Maybe in a future revision.  Another way to shorten these names would
be to use short random garbage as the prefix instead.   That might
make sharing chunks harder, though.

<<Handle dump of [[best]]>>=
// add w/ uniquifier prefix if implicit parms referenced
bool has_ref = has_implref(best, new_parms, best_parms);
string sub_name = has_ref ? newc + "@<<>>" + new_chunk : new_chunk;
ret += "@use " + sub_name + '\n';
// skip if already there
if(chunks.find(sub_name) != chunks.end())
  continue;
// skip if plain reference with no parm refs
if(sub_name == best)
  continue;
subdefs += dump_def(best, sub_name, new_parms);
@

Finding references to implicitly defined parameters requires scanning
every [[@use]] of a parameter for a definition in the global table
which is not in the local table.  Any non-parameter [[@use]] must also
be scanned, recursively, assigning symbol values if that [[@use]] is a
parameterized reference.

<<[[dump_def]] deps>>=
static bool has_implref(const string &chunk, const strmap &impl_parms,
                        const strmap &direct_parms)
{
  const vector<int> &chunkparts = chunks[chunk];
  for(size_t i = 0; i < chunkparts.size(); i += 2) {
    int low = chunkparts[i], high = chunkparts[i + 1];
    for(;low <= high; low++)
      if(!notext[low].cmp_prefix("@use ")) {
        string ref = ltail(notext[low], 5);
        <<Check if [[ref]] is an implicit ref>>
      }
  }
  return false;
}
@

If it is in either symbol table, it is definitely a parameter, so
instead of checking the syntax, a lookup success is acted on
immediately.  On the other hand, if it is a parameter reference, and
both lookups failed, it is ignored.

<<Check if [[ref]] is an implicit ref>>=
if(direct_parms.find(ref) != direct_parms.end())
  continue;
if(impl_parms.find(ref) != impl_parms.end())
  return true;
if(ref[0] == '@')
  continue;
@

For full chunk references, a (possibly parameterized) match is looked
up.  Any implicit references in parameter text must be detected as well.

<<Check if [[ref]] is an implicit ref>>=
string orig = ref;
strmap best_parms;
string best = find_best_def(idx_to_loc(low), orig, best_parms);
if(best.empty())
  continue;
for(strmap::const_iterator p = best_parms.begin(); p != best_parms.end(); p++) {
  const string &v = p->second;
  for(size_t start, vrest = 0; (start = v.find("@<<@", vrest)) != string::npos;
      vrest += 2) {
    vrest = start + 1;
    do {
      vrest = v.find("@>>", vrest + 2);
    } while(vrest != string::npos && v[vrest - 1] == '@');
    if(vrest == string::npos)
      break;
    string subv = v.substr(start + 2, vrest - (start + 2));
    if(impl_parms.find(subv) != impl_parms.end() &&
       direct_parms.find(subv) == direct_parms.end())
      return true;
  }
}
recheck_best(idx_to_loc(i), orig, best, best_parms, impl_parms);
strmap new_impl = merge_strmap(impl_parms, best_parms);
if(has_implref(best, new_impl, best_parms))
  return true;
@

\section{Weaving}

These enhancements also require changes to the weavers.  No particular
effort will be made to typeset things nicely.  Parameter references
should be typeset as chunk references, but without the links (where
would they link to?).  To do that, they need to be hidden from the
indexer, and unhidden after the indexer.  Likewise, to get cross
references right, references to parameterized chunks with actual
parameters need to be converted to the definition format for the
indexer, and then changed back afterwards.  These tasks can be
accomplished by two filters:  one for before indexing, and one for
after.

<<nw-parm-preidx.cpp>>=
<<Common parm C++ Prefix>>

@

<<nw-parm-postidx.cpp>>=
<<Common parm C++ Prefix>>

@

The pre-index filter needs to know how to interpret chunk references
with in-line code:  either as in-line code, or as macro parameters.
The only way to do this is to know the names of all chunks.  Since
weaving does not require all tangling inputs, but this particular task
does require them, any inputs not included in the weaving process must
be specified on the filter's command line.  While it might be nice to
use the standard markup tool for this, it is not present in noweb 3.
Instead, the file is parsed directly, with a very limited view of what
constitutes the start of a chunk.  This probably needs improvement.

Much like the tangler's reader, each definition is placed into two
arrays:  one indexed by its real name, and one indexed by its name
with all parameter definitions and references stripped out.  That way,
finding the actual chunk to use for a macro reference is easier.

<<nw-parm-preidx.cpp>>=
<<[[nw-parm-preidx]] locals>>

int main(int argc, const char **argv)
{
  <<nw-parm-preidx>>
  return 0;
}
@

<<[[nw-parm-preidx]] locals>>=
strsetmap parmchunks;
@

<<nw-parm-preidx>>=
strset chunks;

for(int i = 1; i < argc; i++) {
#if 0
  fh = popen("markup " + argv[i]);  // C++ doesn't have any such function
#else
  ifstream fh(argv[i]);
#endif
  string line;
  while(getline(fh, line).good() || line.size()) {
#if 0
    if(line.cmp_prefix("@defn "))
      continue;
    string chunkname = line.substr(6);
#else
    if(line.cmp_prefix("@<<") ||
       line.substr(line.size() - 3, 3) != "@>>=")
      continue;
    string chunkname = line.substr(2, line.size() - 3);
#endif
    chunks.insert(chunkname);
    string s = strip_chunkname(chunkname);
    parmchunks[s].insert(chunkname);
  }
  fh.close();
}
@

<<Common parm C++ Prefix>>=
#include <fstream>
@

<<[[nw-parm-preidx]] locals>>=
<<[[strip_chunkname]]>>
@

The filter process needs to scan the file more than once.  The first
time, it gathers definitions just like it did for the command-line
arguments.  For convenience, the file is just read into an array of
plain text lines for processing.

<<nw-parm-preidx>>=
vector<string> file;
string line;
while(getline(cin, line).good() || line.size())
  file.push_back(line);
for(size_t i = 0; i < file.size(); i++) {
  if(file[i].cmp_prefix("@defn "))
    continue;
  string chunkname = file[i].substr(6);
  chunks.insert(chunkname);
  string s = strip_chunkname(chunkname);
  parmchunks[s].insert(chunkname);
}
@

For the second pass, an attempt is made to match a chunk reference
with a definition.  If it matches, and requires parameter expansion to
do so, its name is replaced with the parameterized definition, and its
old name is saved using [[@nwparmcall]].  The matching method is
copied from the tangler, with minor differences.  Line and file
information are not tracked by this filter, so the location string is 
always blank.  Also, since a standalone chunk does not have parameter
values, the specialization performed after parameter expansion in chunk
names can't be done.  Unfortunately, there is also no special link
between a parameterized chunk and all of its potential specializations.

Parameter references are simply hidden by renaming them to
[[@nwparmuse]].

As a special hack, in order to highlight parameters better, an extra
set of square brackets is placed around them.  This repeats some of
the work that [[find_best_def]] does, but that's not too terrible.

<<nw-parm-preidx>>=
for(size_t i = 0; i < file.size(); i++) {
  int j;
  if(!file[i].cmp_prefix("@use ") && file[i][5] != '@' &&
     (j = file[i].find("@[[")) && file[i].find("@]]", j + 2)) {
    string chunkname = file[i].substr(5);
    strmap best_parms;
    string best = find_best_def("", chunkname, best_parms);
    if(!best.empty() && best != chunkname) {
      string cur = "";
      int ca = 0, cp, ba = 0, bp;
      while(find_parm(best, bp, ba)) {
        int oca = ca;
        find_parm(chunkname, cp, ca);
	cur += chunkname.substr(oca, cp - oca);
	if(!best.compare(bp, ba - bp, chunkname, cp, ca - cp))
	  cur += chunkname.substr(cp, ca - cp);
	else
	  cur += "[[" + chunkname.substr(cp, ca - cp) + "]]";
      }
      cout << "@nwparmcall " << cur << chunkname.substr(ca) << "\n"
              "@use " << best << '\n';
    } else
      cout << file[i] << '\n';
  } else {
    if(!file[i].cmp_prefix("@use @"))
      cout << "@nwparm" << file[i].substr(1);
    else
      cout << file[i];
    cout << '\n';
  }
}
@

<<[[nw-parm-preidx]] locals>>=
<<[[find_best_def]]>>
@

For the third pass, done after the index, the above-added tags are
reverted.

<<nw-parm-postidx.cpp>>=
int main(void)
{
  string nwparmcall;
  string line;
  while(getline(cin, line).good() || line.size()) {
    if(!line.cmp_prefix("@nwparmcall "))
      nwparmcall = line.substr(12);
    else if(!nwparmcall.empty() && !line.cmp_prefix("@use ")) {
      cout << "@use " << nwparmcall << '\n';
      nwparmcall = "";
    } else if(!line.cmp_prefix("@nwparmuse "))
      cout << '@' << line.substr(7) << '\n';
    else
      cout << line << '\n';
  }
}
@

\section{Other}

This is not the end of it: [[noroots]] (noweb-2 only) needs changes as
well.  There is no reason to retain the pipeline for this tool, so it
could be standalone and not depend on the markup parser.  However,
keeping the parsing to the one official parser might be a good idea.
The [[noroots]] script is not a simple pipeline, though: it includes
the entire ``backend'' in-line.  To make a replacement program, the
library location is lifted using a trick filter in [[notangle]].  This
requires runnig a pipe, which is not possible in standard C++.  As
such, the C equivalents are used.  Also, both the syntax of the
command and file redirection are UNIX-specific (as is the original
noroots, to the most part).  There is no real portable way to do this.

<<Common parm C++ Prefix>>=
extern "C" {
#include <stdio.h>
#include <ctype.h>
#include <string.h>
}
@

<<noroots-parm.cpp>>=
<<Common parm C++ Prefix>>

<<[[noroots-parm]] local definitions>>

int main(int argc, const char **argv)
{
  <<noroots-parm>>
  return 0;
}
@

<<[[noroots-parm]] local definitions>>=
char iobuf[4096];

static bool getline(FILE *f, string &line)
{
  line.clear();
  iobuf[sizeof(iobuf) - 1] = 1;
  while(fgets(iobuf, sizeof(iobuf), f)) {
    if(!iobuf[0])
      return false;
    line += iobuf;
    if(iobuf[sizeof(iobuf) - 1] || iobuf[sizeof(iobuf) - 2] == '\n')
      return true;
    iobuf[sizeof(iobuf) - 1] = 0;
  }
  return false;
}
@

<<noroots-parm>>=
FILE *p = popen("notangle -filter 'echo $LIB >&3' /dev/null 2>/dev/null 3>&1", "r");
if(!p) {
  perror("getting markup location");
  exit(1);
}
string lib;
getline(p, lib);
pclose(p);
while(lib.size() && isspace(lib[lib.size() - 1]))
  lib.erase(lib.size() - 1);
@

The procedure is the same as standard [[noroots]], except that after
collecting all usages, a pass is made over the usage array to add
parameterized usages.

<<[[noroots-parm]] local definitions>>=
strsetmap parmchunks;

<<[[strip_chunkname]]>>
@

<<noroots-parm>>=
strset chunks, use;

// fork() + exec() would be safer, but instead I'll quote the args
string cmd = lib + "/markup";
for(int i = 1; i < argc; i++) {
  cmd += " '";
  const char *s = argv[i];
  for(const char *start = s; (start = strchr(start, '\'')); start++) {
    cmd.append(s, start + 1 - s);
    s = start + 1;
    cmd += "\\''";
  }
  cmd += s;
  cmd += '\'';
}
p = popen(cmd.c_str(), "r");
string line;
while(getline(p, line) || line.size()) {
  if(line == "@quote\n") {
    while(getline(p, line) || line.size())
      if(line == "@endquote\n")
        break;
  } else if(!line.cmp_prefix("@defn ")) {
    string chunkname = ltail(line, 6);
    chunks.insert(chunkname);
    parmchunks[strip_chunkname(chunkname)].insert(chunkname);
  } else if(!line.cmp_prefix("@use "))
    use.insert(ltail(line, 5));
}
<<Add [[use]] entries for parameterized references>>
for(strset::const_iterator d = chunks.begin(); d != chunks.end(); d++)
  if(use.find(*d) == use.end())
    cout @<< "@<<" @<< *d @<< "@>>\n";
@

Direct, fully specified macro calls are easy:  just find the best
match and mark it.

<<[[noroots-parm]] local definitions>>=
<<[[find_best_def]]>>
@

<<Add [[use]] entries for parameterized references>>=
strset ou = use;  // unsafe to insert into unordered_set while iterating
for(strset::const_iterator u = ou.begin(); u != ou.end(); u++)
  if((*u)[0] != '@') {
    strmap best_parms;
    string best = find_best_def("", *u, best_parms);
    if(!best.empty())
      use.insert(best);
  }
@

However, this does not work when passing parameters down.  The
tangling filter also repeatedly resolves variable references as needed
for the best specialization choice.  The only way to check for these
is to check each root, expanding any parameter references, and marking
any newly used definitions.  This would need to be done in two passes:
first to cover unparameterized roots, and then to cover any remaining
parameterized roots.  Thus the entire code above would need to be
rewritten.  Instead, a simple hack is performed: for any usage of a
parameterizable chunk with a passed-on parameter, all possible
specializations of that parameter are marked used as well.  This
(along with the previous loop) may end up marking more than necessary,
but it's probably good enough for a program that isn't really
officially supported, anyway.  One of these days, maybe I'll modify
[[nt-parm]] to perform this function more accurately.

<<noroots-parm>>=
ou = use;
for(strset::const_iterator u = ou.begin(); u != ou.end(); u++) {
  if(u->rfind("@<<@") < 2)  // needs at least one parm ref in code
    continue;
  strsetmap::const_iterator pchunks = parmchunks.find(strip_chunkname(*u));
  if(pchunks == parmchunks.end() ||
     !pchunks->second.size()) // needs possible resolutions
    continue;
  strmap bparms;
  string b = find_best_def("", *u, bparms);
  if(b == *u) // needs to resolve without specialization
    continue;
  // find possible parameters with parameter expansion
  strset vars;
  for(strmap::const_iterator v = bparms.begin(); v != bparms.end(); v++)
    if(v->second.find("@<<@") != string::npos)
      vars.insert(v->second);
  if(!vars.size())
    continue;
  // map vars to var positions
  vector<bool> vpos;
  int brest = 0, bp;
  while(find_parm(b, bp, brest))
    vpos.push_back(b[bp] == '(' &&
                   vars.find(b.substr(bp + 1, brest - bp - 2)) != vars.end());
  // for each possible resolution, allow anything at u's var positions
  // also, allow mapping of any parm to any code text
  for(strset::const_iterator pc = pchunks->second.begin();
      pc != pchunks->second.end(); pc++) {
    if(*pc == b)
      continue;
    bool matched = true;
    int prest = 0, pp, urest = 0, up;
    for(int i = 0; matched && find_parm(*pc, pp, prest); i++) {
      find_parm(*u, up, urest);
      if((*pc)[pp] == '[')
        matched = vpos[i];
      else
        matched = (*u)[up] == '[';
      if(!matched)
        matched = !pc->compare(pp, prest - pp, *u, up, urest - up);
    }
    if(matched)
      use.insert(*pc);
  }
}
@

\section{Usage}

In summary, to use this, see the introduction for syntax.  Extract the
following four chunks from this document, compile them with your C++
compiler into an executable, and use as described:

\begin{itemize}
\item [[nt-parm.cpp]] --- always use this as a filter when tangling.
\item [[nw-parm-preidx.cpp]] --- always use this as a filter when weaving,
before indexing (or implicit indexing, such [[-x]], [[-index]], etc.).
\item [[nw-parm-postidx.cpp]] --- always use this as a filter when
weaving, after indexing (or implicit indexing).  If no indexing is
done at all, use both of these filters with nothing in between.
\item [[noroots-parm.cpp]] --- use this in place of [[noroots]].
\end{itemize}

For example:

To compile on UNIX:
\begin{verbatim}
for x in nt-prm nw-parm-{pre,post}idx noroots-parm; do
  notangle -L -R${x}.cpp parm.nw > ${x}.cpp
  c++ -O -o ${x} ${x.cpp}
done
\end{verbatim}

To use on UNIX, if the executables are in the current directory:
\begin{verbatim}
notangle -filter ./nt-parm -R'myroot' mystuff.nw > out
noweave -filter ./nw-parm-preidx -index \
        -filter ./nw-parm-postidx mystuff.nw > mystuff.tex
\end{verbatim}

If you are weaving a file that is meant to be tangled together with
other files, those other files need to be given on the
[[nw-parm-preidx]] command line.  Repeating the main input file is
harmless.  For example, if [[x.nw]] and [[y.nw]] are normally tangled
together, but weaved separately (again, on UNIX, if the executables
are in the current directory):

\begin{verbatim}
notangle -filter ./nt-parm -R'myroot' x.nw y.nw > out
noweave -filter "./nw-parm-preidx y.nw" -index \
        -filter ./nw-parm-postidx x.nw > x.tex
noweave -filter "./nw-parm-preidx x.nw" -index \
        -filter ./nw-parm-postidx y.nw > y.tex
\end{verbatim}

\section{Index}

\nowebchunks

% note: no identifier indexing is done right now

%\nowebindex

\end{document}

\input{begin-hidden.tex} %%% doc
<<Known Data Types>>=
% C++
vector,set,map,unordered_map,unordered_set,string,std,stringstream,%
const_iterator,%
% Local
strmap,strset,strsetmap,%
@
\input{end-hidden.tex} %%% doc
